{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# References\n# 1. https://www.kaggle.com/ammarnassanalhajali/cnn-with-keras-stater\n# 2. https://www.kaggle.com/vsedelnik/happywhale-dataset-image-normalization","metadata":{"execution":{"iopub.status.busy":"2022-02-22T12:26:42.335426Z","iopub.execute_input":"2022-02-22T12:26:42.336829Z","iopub.status.idle":"2022-02-22T12:26:42.370913Z","shell.execute_reply.started":"2022-02-22T12:26:42.336450Z","shell.execute_reply":"2022-02-22T12:26:42.369847Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport sys\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mplimg\nfrom matplotlib.pyplot import imshow\nfrom tqdm.autonotebook import tqdm\n\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\n\nimport keras.backend as K\nfrom keras.models import Sequential\nfrom keras import layers\nfrom keras.preprocessing import image\nfrom keras.applications.imagenet_utils import preprocess_input\nfrom keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv2D\nfrom keras.layers import AveragePooling2D, MaxPooling2D, Dropout\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom keras.models import Model\n\nimport warnings\nwarnings.filterwarnings('ignore', category=DeprecationWarning)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-22T12:26:42.373113Z","iopub.execute_input":"2022-02-22T12:26:42.373810Z","iopub.status.idle":"2022-02-22T12:26:51.623036Z","shell.execute_reply.started":"2022-02-22T12:26:42.373763Z","shell.execute_reply":"2022-02-22T12:26:51.621583Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/happy-whale-and-dolphin/train.csv')\nprint(f\"Shape of TrainSet: {train.shape}\\n\")\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-22T12:26:51.626264Z","iopub.execute_input":"2022-02-22T12:26:51.627355Z","iopub.status.idle":"2022-02-22T12:26:51.827745Z","shell.execute_reply.started":"2022-02-22T12:26:51.627283Z","shell.execute_reply":"2022-02-22T12:26:51.823639Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Functions\n\ndef Loading_Images(data, m, dataset):\n    print(\"Loading Images\")\n    X_train = np.zeros((m, 32, 32, 3))    # 높이*행*열*채널\n    count = 0\n    for fig in tqdm(data['image']):\n        img = image.load_img(\"../input/happy-whale-and-dolphin/\"+dataset+'/'+fig,\n                             target_size=(32, 32, 3))\n        x = image.img_to_array(img)\n        x = preprocess_input(x)\n        X_train[count] = x\n        count += 1\n    return X_train\n# X_train 생성(zero matrix) > Image load > Convert to Array > Normalization > X_train\n# preprocess_input: 이미지를 -255에서 255사이로 Normalization하고 RGB값을 BGR값으로 변경합니다. BGR을RGB로 변경하던가\n \ndef prepare_labels(y):\n    values = np.array(y)\n    label_encoder = LabelEncoder()\n    integer_encoded = label_encoder.fit_transform(values)\n    onehot_encoder = OneHotEncoder(sparse=False)    # default: True(matrix 반환)\n    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n    y = onehot_encoded\n    return y, label_encoder\n# label encoding: 순서대로 숫자 할당\n# onehot encoding: 더미화","metadata":{"execution":{"iopub.status.busy":"2022-02-22T12:27:22.471819Z","iopub.execute_input":"2022-02-22T12:27:22.472996Z","iopub.status.idle":"2022-02-22T12:27:22.484320Z","shell.execute_reply.started":"2022-02-22T12:27:22.472926Z","shell.execute_reply":"2022-02-22T12:27:22.482819Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"X = Loading_Images(train, train.shape[0], 'train_images')\nX /= 255","metadata":{"execution":{"iopub.status.busy":"2022-02-22T12:26:51.852336Z","iopub.execute_input":"2022-02-22T12:26:51.852673Z","iopub.status.idle":"2022-02-22T12:26:59.786488Z","shell.execute_reply.started":"2022-02-22T12:26:51.852638Z","shell.execute_reply":"2022-02-22T12:26:59.784601Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"y, label_encoder = prepare_labels(train['individual_id'])","metadata":{"execution":{"iopub.status.busy":"2022-02-22T12:27:24.800002Z","iopub.execute_input":"2022-02-22T12:27:24.801249Z","iopub.status.idle":"2022-02-22T12:27:25.190014Z","shell.execute_reply.started":"2022-02-22T12:27:24.801195Z","shell.execute_reply":"2022-02-22T12:27:25.188941Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(32,\n                (6,6),\n                strides=(1,1),\n                input_shape-(32, 32, 3)))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Activation('relu'))\n\nmodel.add(MaxPooling2D((2,2)))\nmodel.add(Conv2D(64,\n                (3, 3),\n                strides=(1,1)))\nmodel.add(Activation('relu'))\nmodel.add(AveragePooling2D((3,3)))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.85))\n\nmodel.add(Dense(y.shape[1], activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-22T12:27:30.497761Z","iopub.execute_input":"2022-02-22T12:27:30.498806Z","iopub.status.idle":"2022-02-22T12:27:30.511704Z","shell.execute_reply.started":"2022-02-22T12:27:30.498752Z","shell.execute_reply":"2022-02-22T12:27:30.510028Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"history = model.fit(X, y, epochs=150, batch_size=128, verbose=1)\nmodel.save('/last.h5')","metadata":{"execution":{"iopub.status.busy":"2022-02-22T12:27:33.204729Z","iopub.execute_input":"2022-02-22T12:27:33.205131Z","iopub.status.idle":"2022-02-22T12:27:33.243746Z","shell.execute_reply.started":"2022-02-22T12:27:33.205093Z","shell.execute_reply":"2022-02-22T12:27:33.242270Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Evaluation\n\nplt.figure(figsize=(15, 5))\nplt.plot(history.history['accuracy'])\nplt.title('Model Accuracy')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-22T12:27:36.305009Z","iopub.execute_input":"2022-02-22T12:27:36.305555Z","iopub.status.idle":"2022-02-22T12:27:36.352812Z","shell.execute_reply.started":"2022-02-22T12:27:36.305519Z","shell.execute_reply":"2022-02-22T12:27:36.351503Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 5))\nplt.plot(history.history['loss'])\nplt.title(\"Model Loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-22T12:27:36.439866Z","iopub.execute_input":"2022-02-22T12:27:36.440911Z","iopub.status.idle":"2022-02-22T12:27:36.482893Z","shell.execute_reply.started":"2022-02-22T12:27:36.440851Z","shell.execute_reply":"2022-02-22T12:27:36.481151Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Inference\n\ntest = os.listdir(\"../input/happy-whale-and-dolphin/test_images\")\nprint(len(test))","metadata":{"execution":{"iopub.status.busy":"2022-02-22T12:27:47.689301Z","iopub.execute_input":"2022-02-22T12:27:47.689660Z","iopub.status.idle":"2022-02-22T12:27:48.274105Z","shell.execute_reply.started":"2022-02-22T12:27:47.689626Z","shell.execute_reply":"2022-02-22T12:27:48.273238Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"col = ['image']\ntest_df = pd.DataFrame(test, columns=col)\ntest_df['predictions'] = ''","metadata":{"execution":{"iopub.status.busy":"2022-02-22T12:27:48.275502Z","iopub.execute_input":"2022-02-22T12:27:48.275891Z","iopub.status.idle":"2022-02-22T12:27:48.285525Z","shell.execute_reply.started":"2022-02-22T12:27:48.275862Z","shell.execute_reply":"2022-02-22T12:27:48.284828Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"batch_size=5000\nbatch_start=0\nbatch_end = batch_size\nL = len(test_df)\n\nwhile batch_start < L:\n    limit = min(batch_end, L)\n    test_df_batch = test_df.iloc[batch_start:limit]\n    print(type(test_df_batch))\n    X = Loading_Images(test_df_batch, test_df_batch.shape[0], 'test_images')\n    X /= 255\n    predictions = model.predicct(np.array(X), verbose=1)\n    \n    for i, pred in enumerate(predictions):\n        p = pred.argsort()[-5:][::-1]    # 5번째부터 역순 정렬\n        idx = -1\n        s, s1, s2 = '', '', ''\n        for x in p:\n            idx = idx+1\n            if pred[x] > 0.6:\n                s1 = s1+' '+label_encoder.inverse_transform(p)[idx]\n            else:\n                s2 = s2+' '+label_encoder.inverse_transform(p)[idx]\n        print(s1, s2)\n        s = s1+' new_individual'+s2\n        s = s.strip(' ')\n        test_df.loc[batch_start+i, 'predictions'] = s\n    batch_start += batch_size\n    batch_end += batch_size\n    ","metadata":{"execution":{"iopub.status.busy":"2022-02-22T12:27:48.286882Z","iopub.execute_input":"2022-02-22T12:27:48.287344Z","iopub.status.idle":"2022-02-22T12:31:23.083084Z","shell.execute_reply.started":"2022-02-22T12:27:48.287312Z","shell.execute_reply":"2022-02-22T12:31:23.080989Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"test_df.to_csv(\"submission.csv\", index=False)\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-22T12:26:59.808586Z","iopub.status.idle":"2022-02-22T12:26:59.809733Z","shell.execute_reply.started":"2022-02-22T12:26:59.809464Z","shell.execute_reply":"2022-02-22T12:26:59.809501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Image Normalization","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:56:14.594995Z","iopub.execute_input":"2022-02-19T09:56:14.595354Z","iopub.status.idle":"2022-02-19T09:56:14.615517Z","shell.execute_reply.started":"2022-02-19T09:56:14.595257Z","shell.execute_reply":"2022-02-19T09:56:14.6148Z"}}},{"cell_type":"code","source":"import os\nimport random\nfrom multiprocessing import Pool\nimport cv2\nimport albumentations as A\nINPUT_PATH = '../input/happy-whale-and-dolphin'","metadata":{"execution":{"iopub.status.busy":"2022-02-22T12:31:25.467682Z","iopub.execute_input":"2022-02-22T12:31:25.468351Z","iopub.status.idle":"2022-02-22T12:31:27.410695Z","shell.execute_reply.started":"2022-02-22T12:31:25.468280Z","shell.execute_reply":"2022-02-22T12:31:27.409412Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"train_files = os.listdir(os.path.join(INPUT_PATH, 'train_images'))\ntest_files = os.listdir(os.path.join(INPUT_PATH, 'test_images'))\nall_files = [os.path.join(INPUT_PATH, 'train_images', f) for f in train_files]+ \\\n            [os.path.join(INPUT_PATH, 'test_images', f) for f in test_files]\n\nprint(f\"Train files:{len(train_files)}, test_files: {len(test_files)}, all_files: {len(all_files)}\")\n\nshow_images = random.sample(all_files, 5)","metadata":{"execution":{"iopub.status.busy":"2022-02-22T12:31:27.412630Z","iopub.execute_input":"2022-02-22T12:31:27.412877Z","iopub.status.idle":"2022-02-22T12:31:28.567879Z","shell.execute_reply.started":"2022-02-22T12:31:27.412850Z","shell.execute_reply":"2022-02-22T12:31:28.566282Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def show_orig_norm_images(img_files, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n    nrows, ncols = len(img_files), 2\n    fig, ax = plt.subplots(nrows, ncols, figsize=(20, 31))\n    for i in range(len(img_files)):\n        img = cv2.imread(img_files[i])\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        norm_img = A.Normalize(mean=mean, std=std)(image=img)['image']\n        print(img.shape)\n        print(norm_img[0])\n        ax[i, 0].grid(False)\n        ax[i, 0].axis('off')\n        ax[i, 0].title.set_text(f'{os.path.basename(img_files[i])}: original')\n        ax[i, 0].imshow(img)\n        \n        ax[i, 1].grid(False)\n        ax[i, 1].axis('off')\n        ax[i, 1].title.set_text(f'{os.path.basename(img_files[i])}: normalized')\n        ax[i, 1].imshow(norm_img)\n        \n        plt.tight_layout()\n        plt.show()\n        \nshow_orig_norm_images(show_images)","metadata":{"execution":{"iopub.status.busy":"2022-02-22T12:31:28.569561Z","iopub.execute_input":"2022-02-22T12:31:28.570627Z","iopub.status.idle":"2022-02-22T12:31:32.912799Z","shell.execute_reply.started":"2022-02-22T12:31:28.570541Z","shell.execute_reply":"2022-02-22T12:31:32.911454Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# 각 이미지별, 각 컬러 채널별 픽셀 평균, 분산 계산\n# 이후 평균, 분산은 데이터셋의 모든 이미지들에 대해 평균","metadata":{"execution":{"iopub.status.busy":"2022-02-22T12:26:59.819974Z","iopub.status.idle":"2022-02-22T12:26:59.820423Z","shell.execute_reply.started":"2022-02-22T12:26:59.820205Z","shell.execute_reply":"2022-02-22T12:26:59.820227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.set_printoptions(precisions=3)\n\nall_files = all_files[:1000]\n\ndef process_file(fp):\n    img = cv2.imread(fp)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = img / 255\n    return np.mean(img, axis=(0, 1)), np.std(img, axis=(0, 1))\n\nmean, std = np.zeros(3), np.zeros(3)\nn, done = len(all_files), 0\n\nwith Pool(os.cpu_count()) as p:\n    pbar = tqdm(p.imap(process_file, all_files), total=n)\n    for m, s in pbar:\n        done += 1\n        mean += m\n        std += s\n        pbar.set_description(f\"{mean/done} {std/done}\")\n        \nmean, std = mean/n, std/n\n\nprint(f\"Calculated mean: {mean}\")\nprint(f\"Calculated std: {std}\")","metadata":{"execution":{"iopub.status.busy":"2022-02-22T12:31:32.916616Z","iopub.execute_input":"2022-02-22T12:31:32.916879Z","iopub.status.idle":"2022-02-22T12:31:33.009631Z","shell.execute_reply.started":"2022-02-22T12:31:32.916850Z","shell.execute_reply":"2022-02-22T12:31:33.007816Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"Normalize는 입력 받은 이미지 값의 범위를 (0, 255) → (-1, 1) 범위로 줄여주는 역할\n\n이와 같이 하는 이유는 입력 값의 범위를 줄여줌으로써 학습이 빨리 수렴되게 하고 특정 입력값이 커짐으로써 특정 weight값이 커지는 문제를 개선할 수 있음\n\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}